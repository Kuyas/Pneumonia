{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_ARRAY = [1,5,10,15,30]\n",
    "BATCH_SIZE_ARRAY = [1,2,4,8,10,16,24]\n",
    "TRAIN_SIZE_ARRAY = [200,400,600,800,-1]\n",
    "\n",
    "EPOCHS = EPOCHS_ARRAY[0]\n",
    "TRAIN_BATCH_SIZE = BATCH_SIZE_ARRAY[4]\n",
    "TRAIN_SIZE = TRAIN_SIZE_ARRAY[2]\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "LEARNING_RATE = 0.0003\n",
    "TRAIN_DATAPATH = 'chest_xray\\\\train'\n",
    "VAL_DATAPATH = 'chest_xray\\\\val'\n",
    "TEST_DATAPATH = 'chest_xray\\\\test'\n",
    "TRAIN_TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "    transforms.RandomRotation(degrees = 15),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "VAL_TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize(size=256),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATAPATH, transform=TRAIN_TRANSFORM_IMG)\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True,num_workers=4)\n",
    "val_data = torchvision.datasets.ImageFolder(root=TEST_DATAPATH, transform=VAL_TRANSFORM_IMG)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=4)\n",
    "test_data = torchvision.datasets.ImageFolder(root=TEST_DATAPATH, transform=VAL_TRANSFORM_IMG)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=4)\n",
    "\n",
    "print_row = []\n",
    "# def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "#     npimg = img.numpy()\n",
    "#     plt.figure(figsize=(20,20))\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# dataiter = iter(train_data_loader)\n",
    "# images, labels = dataiter.next()\n",
    "# # show images\n",
    "# imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples:  5216\n",
      "Number of Test Examples:  624\n",
      "Number of Valid Examples:  624\n",
      "Detected Classes are:  {'NORMAL': 0, 'PNEUMONIA': 1}\n",
      "Image Shape on Batch size = torch.Size([10, 3, 224, 224]) \n",
      "cuda:0\n",
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "    (4): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Training Examples: \", len(train_data))\n",
    "print(\"Number of Test Examples: \", len(test_data))\n",
    "print(\"Number of Valid Examples: \", len(val_data))\n",
    "print(\"Detected Classes are: \", train_data.class_to_idx)\n",
    "train_iter = iter(train_data_loader)\n",
    "images, labels_ = train_iter.next()\n",
    "print(\"Image Shape on Batch size = {} \".format(images.size()))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = models.vgg19(True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier[6] = nn.Sequential(nn.Linear(4096, 256), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(256, 2),                   \n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "print(model.classifier)\n",
    "    \n",
    "model.to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(_params, lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  0\n",
      "Epoch 1/1, Training Loss: 0.319, Training Accuracy: 65.000, Validation Loss: 0.013, Validation Acc: 81.000, Time: 66.157s\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    print(\"EPOCH: \",epoch)\n",
    "    correct = 0 \n",
    "    iterations = 0\n",
    "    iter_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i,data in enumerate(train_data_loader,0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        iter_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "        iterations += 1\n",
    "        if(iterations == TRAIN_SIZE):\n",
    "            break\n",
    "    \n",
    "    train_loss.append(iter_loss/iterations)\n",
    "    # Record the training accuracy\n",
    "    train_accuracy.append((100 * correct / len(train_data)))\n",
    "    \n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    model.eval()\n",
    "\n",
    "    for i, data in enumerate(val_data_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(inputs)     \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "        iterations+=1\n",
    "\n",
    "    test_loss.append(loss/iterations)\n",
    "    # Record the Testing accuracy\n",
    "    test_accuracy.append((100 * correct / len(val_data)))\n",
    "    stop = time.time()\n",
    "    print ('Epoch {}/{}, Training Loss: {:.3f}, Training Accuracy: {:.3f}, Validation Loss: {:.3f}, Validation Acc: {:.3f}, Time: {:.3f}s'\n",
    "           .format(epoch+1, EPOCHS, train_loss[-1], train_accuracy[-1], test_loss[-1], test_accuracy[-1], stop-start))\n",
    "\n",
    "    row = [epoch+1,train_loss[-1],train_accuracy[-1].item(),test_loss[-1].item(),test_accuracy[-1].item(),stop-start]\n",
    "    print_row.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n",
      "624\n",
      "Testing accuracy: 81.25\n",
      "tensor([[134., 100.],\n",
      "        [ 17., 373.]])\n",
      "Accuracy of NORMAL : 52 %\n",
      "Accuracy of PNEUMONIA : 94 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "classes =['NORMAL','PNEUMONIA']\n",
    "confusion_matrix = torch.zeros(2, 2)\n",
    "correct_0 = 0\n",
    "correct_1 = 0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "with torch.no_grad():\n",
    "    for data in test_data_loader:\n",
    "        images,labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "        correct+=(predicted == labels).sum().item()\n",
    "        for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "acc = 100*correct/total\n",
    "print(correct)\n",
    "print(total)\n",
    "print('Testing accuracy: ' + str(acc))\n",
    "print(confusion_matrix)\n",
    "\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "acc0 = 100 * class_correct[0] / class_total[0]\n",
    "acc1 = 100 * class_correct[1] / class_total[1]\n",
    "print_row_end = []\n",
    "row_end = [acc,acc0,acc1]\n",
    "print_row_end.append(row_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"vgg19+base_\"+str(TRAIN_BATCH_SIZE)+\"_\"+str(TRAIN_SIZE)+\"_\"+str(EPOCHS)\n",
    "heading = []\n",
    "footer = []\n",
    "heading.append([\"Epoch Number\", 'Training Loss', 'Training Accuracy','Validation Loss','Validation Acc', 'Time' ])\n",
    "footer.append(['Testing Accuracy','Accuracy of Normal', 'Accuracy of Pneumonia'])\n",
    "with open('Save/'+filename+'.csv', mode='w',newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerows(heading)\n",
    "    writer.writerows(print_row)\n",
    "    writer.writerows(footer)\n",
    "    writer.writerows(print_row_end)\n",
    "import winsound\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:  1.2.0\n",
      "CUDA available:  True\n",
      "CUDA version:  10.0\n",
      "vgg19+base_10_400_1\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version: \", torch.__version__ )\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "print(\"CUDA version: \", torch.version.cuda)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
